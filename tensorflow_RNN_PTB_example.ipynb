{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!wget http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz\n",
    "#!tar xvf simple-examples.tgz\n",
    "#!rm simple-examples.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-train\t\t   5-one-iter\t\t       9-char-based-lm\ttemp\r\n",
      "2-nbest-rescore    6-recovery-during-training  data\r\n",
      "3-combination\t   7-dynamic-evaluation        models\r\n",
      "4-data-generation  8-direct\t\t       rnnlm-0.2b\r\n"
     ]
    }
   ],
   "source": [
    "!ls simple-examples/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SmallConfig(object):\n",
    "  \"\"\"Small config.\"\"\"\n",
    "  init_scale = 0.1\n",
    "  learning_rate = 1.0\n",
    "  max_grad_norm = 5\n",
    "  num_layers = 2\n",
    "  num_steps = 25\n",
    "  hidden_size = 200\n",
    "  max_epoch = 4\n",
    "  max_max_epoch = 13\n",
    "  keep_prob = 1.0\n",
    "  lr_decay = 0.5\n",
    "  batch_size = 20\n",
    "  vocab_size = 10000\n",
    "\n",
    "\n",
    "class MediumConfig(object):\n",
    "  \"\"\"Medium config.\"\"\"\n",
    "  init_scale = 0.05\n",
    "  learning_rate = 1.0\n",
    "  max_grad_norm = 5\n",
    "  num_layers = 2\n",
    "  num_steps = 35\n",
    "  hidden_size = 650\n",
    "  max_epoch = 6\n",
    "  max_max_epoch = 39\n",
    "  keep_prob = 0.5\n",
    "  lr_decay = 0.8\n",
    "  batch_size = 20\n",
    "  vocab_size = 10000\n",
    "\n",
    "\n",
    "class LargeConfig(object):\n",
    "  \"\"\"Large config.\"\"\"\n",
    "  init_scale = 0.04\n",
    "  learning_rate = 1.0\n",
    "  max_grad_norm = 10\n",
    "  num_layers = 2\n",
    "  num_steps = 35\n",
    "  hidden_size = 1500\n",
    "  max_epoch = 14\n",
    "  max_max_epoch = 55\n",
    "  keep_prob = 0.35\n",
    "  lr_decay = 1 / 1.15\n",
    "  batch_size = 20\n",
    "  vocab_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.models.rnn.ptb import reader\n",
    "\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " aer banknote berlitz calloway centrust cluett fromstein gitano guterman hydro-quebec ipo kia memotec mlx nahb punts rake regatta rubens sim snack-food ssangyong swapo wachter \r\n",
      " pierre <unk> N years old will join the board as a nonexecutive director nov. N \r\n",
      " mr. <unk> is chairman of <unk> n.v. the dutch publishing group \r\n",
      " rudolph <unk> N years old and former chairman of consolidated gold fields plc was named a nonexecutive director of this british industrial conglomerate \r\n",
      " a form of asbestos once used to make kent cigarette filters has caused a high percentage of cancer deaths among a group of workers exposed to it more than N years ago researchers reported \r\n",
      " the asbestos fiber <unk> is unusually <unk> once it enters the <unk> with even brief exposures to it causing symptoms that show up decades later researchers said \r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(929589, [9970, 9971, 9972, 9974, 9975, 9976, 9980, 9981, 9982, 9983]),\n",
       " (73760, [1132, 93, 358, 5, 329, 51, 9836, 6, 326, 2476]),\n",
       " (82430, [102, 14, 24, 32, 752, 381, 2, 29, 120, 0])]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = reader.ptb_raw_data(\"./simple-examples/data/\")\n",
    "train_data, valid_data, test_data, _ = raw_data\n",
    "\n",
    "!head -n6 simple-examples/data/ptb.train.txt\n",
    "[(len(x),x[:10]) if type(x) == list else (x,) for x in raw_data[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = SmallConfig()\n",
    "\n",
    "input_data_train, targets_train = reader.ptb_producer(train_data, config.batch_size, config.num_steps)\n",
    "input_data_test, targets_test = reader.ptb_producer(test_data, config.batch_size, config.num_steps)\n",
    "input_data_valid, targets_valid = reader.ptb_producer(valid_data, config.batch_size, config.num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_data, targets = input_data_train, targets_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!wget http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz\n",
    "!tar xvf simple-examples.tgz\n",
    "\n",
    "raw_data = reader.ptb_raw_data(\"./simple-examples/data/\")\n",
    "train_data, valid_data, test_data, _ = raw_data\n",
    "\n",
    "input_data, targets = reader.ptb_producer(train_data, 20, 25)\n",
    "cell = tf.nn.rnn_cell.BasicLSTMCell(200, forget_bias=1.0, state_is_tuple=True)\n",
    "initial_state = cell.zero_state(20, tf.float32)\n",
    "embedding = tf.get_variable(\"embedding\", [10000, 200], dtype=tf.float32)\n",
    "inputs = tf.nn.embedding_lookup(embedding, input_data)\n",
    "\n",
    "input_data_train # <tf.Tensor 'PTBProducer/Slice:0' shape=(20, 25) dtype=int32>\n",
    "inputs # <tf.Tensor 'embedding_lookup:0' shape=(20, 25, 200) dtype=float32>\n",
    "\n",
    "outputs = []\n",
    "state = initial_state\n",
    "for time_step in range(25):\n",
    "    if time_step > 0: \n",
    "        tf.get_variable_scope().reuse_variables()\n",
    "        \n",
    "    cell_output, state = cell(inputs[:, time_step, :], state)\n",
    "    outputs.append(cell_output)\n",
    "    \n",
    "output = tf.reshape(tf.concat(1, outputs), [-1, 200])\n",
    "\n",
    "outputs # list of 20: <tf.Tensor 'BasicLSTMCell/mul_2:0' shape=(20, 200) dtype=float32>\n",
    "output # <tf.Tensor 'Reshape_2:0' shape=(500, 200) dtype=float32>\n",
    "\n",
    "softmax_w = tf.get_variable(\"softmax_w\", [config.hidden_size, config.vocab_size], dtype=tf.float32)\n",
    "softmax_b = tf.get_variable(\"softmax_b\", [config.hidden_size, config.vocab_size], dtype=tf.float32)\n",
    "logits = tf.matmul(output, softmax_w) + softmax_b\n",
    "\n",
    "loss = tf.nn.seq2seq.sequence_loss_by_example([logits], [tf.reshape(targets, [-1])],[tf.ones([20*25], dtype=tf.float32)])\n",
    "cost = tf.reduce_sum(loss) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(config.hidden_size, forget_bias=0.0, state_is_tuple=True)\n",
    "\n",
    "if config.keep_prob < 1.0:\n",
    "    lstm_cell = tf.nn.rnn_cell.DropoutWrapper(lstm_cell, output_keep_prob=config.keep_prob)\n",
    "\n",
    "cell = tf.nn.rnn_cell.MultiRNNCell([lstm_cell] * config.num_layers, state_is_tuple=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initial_state = cell.zero_state(config.batch_size, tf.float32)\n",
    "\n",
    "embedding = tf.get_variable(\"embedding\", [config.vocab_size, config.hidden_size], dtype=tf.float32)\n",
    "inputs = tf.nn.embedding_lookup(embedding, input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'PTBProducer/Slice:0' shape=(20, 25) dtype=int32>,\n",
       " <tf.Tensor 'embedding_lookup:0' shape=(20, 25, 200) dtype=float32>,\n",
       " 10000,\n",
       " 200)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data_train, inputs, config.vocab_size, config.hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outputs = []\n",
    "state = initial_state\n",
    "for time_step in range(config.num_steps):\n",
    "    if time_step > 0: \n",
    "        tf.get_variable_scope().reuse_variables()\n",
    "        \n",
    "    cell_output, state = cell(inputs[:, time_step, :], state)\n",
    "    outputs.append(cell_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'MultiRNNCell_3/Cell1/BasicLSTMCell/mul_2:0' shape=(20, 200) dtype=float32>,\n",
       " <tf.Tensor 'concat_7:0' shape=(20, 5000) dtype=float32>,\n",
       " <tf.Tensor 'Reshape_2:0' shape=(500, 200) dtype=float32>,\n",
       " 10000,\n",
       " 200)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0], tf.concat(1, outputs), tf.reshape(tf.concat(1, outputs), [-1, config.hidden_size]), config.vocab_size, config.hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'MultiRNNCell_3/Cell1/BasicLSTMCell/mul_2:0' shape=(20, 200) dtype=float32>,\n",
       " <tf.Tensor 'MultiRNNCell_4/Cell1/BasicLSTMCell/mul_2:0' shape=(20, 200) dtype=float32>,\n",
       " <tf.Tensor 'MultiRNNCell_5/Cell1/BasicLSTMCell/mul_2:0' shape=(20, 200) dtype=float32>,\n",
       " <tf.Tensor 'MultiRNNCell_6/Cell1/BasicLSTMCell/mul_2:0' shape=(20, 200) dtype=float32>,\n",
       " <tf.Tensor 'MultiRNNCell_7/Cell1/BasicLSTMCell/mul_2:0' shape=(20, 200) dtype=float32>,\n",
       " <tf.Tensor 'MultiRNNCell_8/Cell1/BasicLSTMCell/mul_2:0' shape=(20, 200) dtype=float32>,\n",
       " <tf.Tensor 'MultiRNNCell_9/Cell1/BasicLSTMCell/mul_2:0' shape=(20, 200) dtype=float32>,\n",
       " <tf.Tensor 'MultiRNNCell_10/Cell1/BasicLSTMCell/mul_2:0' shape=(20, 200) dtype=float32>,\n",
       " <tf.Tensor 'MultiRNNCell_11/Cell1/BasicLSTMCell/mul_2:0' shape=(20, 200) dtype=float32>,\n",
       " <tf.Tensor 'MultiRNNCell_12/Cell1/BasicLSTMCell/mul_2:0' shape=(20, 200) dtype=float32>,\n",
       " <tf.Tensor 'MultiRNNCell_13/Cell1/BasicLSTMCell/mul_2:0' shape=(20, 200) dtype=float32>,\n",
       " <tf.Tensor 'MultiRNNCell_14/Cell1/BasicLSTMCell/mul_2:0' shape=(20, 200) dtype=float32>,\n",
       " <tf.Tensor 'MultiRNNCell_15/Cell1/BasicLSTMCell/mul_2:0' shape=(20, 200) dtype=float32>,\n",
       " <tf.Tensor 'MultiRNNCell_16/Cell1/BasicLSTMCell/mul_2:0' shape=(20, 200) dtype=float32>,\n",
       " <tf.Tensor 'MultiRNNCell_17/Cell1/BasicLSTMCell/mul_2:0' shape=(20, 200) dtype=float32>,\n",
       " <tf.Tensor 'MultiRNNCell_18/Cell1/BasicLSTMCell/mul_2:0' shape=(20, 200) dtype=float32>,\n",
       " <tf.Tensor 'MultiRNNCell_19/Cell1/BasicLSTMCell/mul_2:0' shape=(20, 200) dtype=float32>,\n",
       " <tf.Tensor 'MultiRNNCell_20/Cell1/BasicLSTMCell/mul_2:0' shape=(20, 200) dtype=float32>,\n",
       " <tf.Tensor 'MultiRNNCell_21/Cell1/BasicLSTMCell/mul_2:0' shape=(20, 200) dtype=float32>,\n",
       " <tf.Tensor 'MultiRNNCell_22/Cell1/BasicLSTMCell/mul_2:0' shape=(20, 200) dtype=float32>,\n",
       " <tf.Tensor 'MultiRNNCell_23/Cell1/BasicLSTMCell/mul_2:0' shape=(20, 200) dtype=float32>,\n",
       " <tf.Tensor 'MultiRNNCell_24/Cell1/BasicLSTMCell/mul_2:0' shape=(20, 200) dtype=float32>,\n",
       " <tf.Tensor 'MultiRNNCell_25/Cell1/BasicLSTMCell/mul_2:0' shape=(20, 200) dtype=float32>,\n",
       " <tf.Tensor 'MultiRNNCell_26/Cell1/BasicLSTMCell/mul_2:0' shape=(20, 200) dtype=float32>,\n",
       " <tf.Tensor 'MultiRNNCell_27/Cell1/BasicLSTMCell/mul_2:0' shape=(20, 200) dtype=float32>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = tf.reshape(tf.concat(1, outputs), [-1, config.hidden_size])\n",
    "softmax_w = tf.get_variable(\"softmax_w\", [config.hidden_size, config.vocab_size], dtype=tf.float32)\n",
    "softmax_b = tf.get_variable(\"softmax_b\", [config.hidden_size, config.vocab_size], dtype=tf.float32)\n",
    "logits = tf.matmul(output, softmax_w) + softmax_b\n",
    "\n",
    "loss = tf.nn.seq2seq.sequence_loss_by_example([logits], [tf.reshape(targets, [-1])], [tf.ones([batch_size*num_steps], dtype=tf.float32)])\n",
    "\n",
    "logits = tf.matmul(output, softmax_w) + softmax_b\n",
    "loss = tf.nn.seq2seq.sequence_loss_by_example(\n",
    "    [logits],\n",
    "    [tf.reshape(input_.targets, [-1])],\n",
    "    [tf.ones([batch_size * num_steps], dtype=data_type())])\n",
    "cost = tf.reduce_sum(loss) / batch_size\n",
    "final_state = state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
